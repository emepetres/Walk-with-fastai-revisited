{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a9b5b8-b507-411d-a0ab-bb00eb2c475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.vision.data import imagenet_stats\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "dataset_path = untar_data(URLs.PETS)\n",
    "dataset_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c9b3b2-afb8-4265-b81d-bfd55ef00cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f4f689-b0f0-4674-a328-1331d96a7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.transforms import CenterCrop, RandomResizedCrop, ToTensor, Normalize\n",
    "\n",
    "train_transforms = nn.Sequential(\n",
    "    RandomResizedCrop((224,224)),\n",
    "    Normalize(*imagenet_stats)\n",
    ")\n",
    "\n",
    "valid_transforms = nn.Sequential(\n",
    "    CenterCrop((224,224)),\n",
    "    Normalize(*imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82db4e5b-ba00-4aed-9f8a-0716c7459a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# This example is highly based on the work of Sylvain Gugger\n",
    "# for the Accelerate notebook example which can be found here: \n",
    "# https://github.com/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_cv_example.ipynb\n",
    "class PetsDataset(Dataset):\n",
    "    \"A basic dataset that will return a tuple of (image, label)\"\n",
    "    def __init__(self, filenames:list, transforms:nn.Sequential, label_to_int:dict):\n",
    "        self.filenames = filenames\n",
    "        self.transforms = transforms\n",
    "        self.label_to_int = label_to_int\n",
    "        self.to_tensor = ToTensor()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def apply_x_transforms(self, filename):\n",
    "        image = Image.open(filename).convert(\"RGB\")\n",
    "        tensor_image = self.to_tensor(image)\n",
    "        return self.transforms(tensor_image)\n",
    "    \n",
    "    def apply_y_transforms(self, filename):\n",
    "        label = re.findall(r\"^(.*)_\\d+\\.jpg$\", filename.name)[0].lower()\n",
    "        return self.label_to_int[label]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        x = self.apply_x_transforms(filename)\n",
    "        y = self.apply_y_transforms(filename)\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebc33fd-3fb2-4af7-9f7b-850998a744f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pat = r\"^(.*)_\\d+\\.jpg$\"\n",
    "filenames = (dataset_path/'images').ls(file_exts=\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10be2949-af5f-4bdd-977b-1235eedfb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = filenames.map(\n",
    "    lambda x: re.findall(label_pat, x.name)[0].lower()\n",
    ").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9d3be0-cb05-493d-8b39-c73620d78465",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7003a6-05d3-4254-8f44-14fe57810c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int = {index:key for key, index in enumerate(labels)}\n",
    "label_to_int.keys(), label_to_int[\"siamese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b0de16b-e7dc-4f11-856f-2195a8f7673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shuffled_indexes = np.random.permutation(len(filenames))\n",
    "split = int(0.8 * len(filenames))\n",
    "train_indexes, valid_indexes = (\n",
    "    shuffled_indexes[:split], shuffled_indexes[split:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc8df81-cee4-434c-acf1-af9f6842d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fnames = filenames[train_indexes]\n",
    "valid_fnames = filenames[valid_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6292ed9f-445b-43d0-98fc-6d5bbb936374",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PetsDataset(\n",
    "    train_fnames,\n",
    "    train_transforms,\n",
    "    label_to_int\n",
    ")\n",
    "\n",
    "valid_dataset = PetsDataset(\n",
    "    valid_fnames,\n",
    "    valid_transforms,\n",
    "    label_to_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aba8412a-db63-4fd1-bf65-9bd9648eaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_dataset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236646dd-6fd4-469e-a8f0-2a165bc924d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e691d373-5817-4a48-9b1c-77933234f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40639473-c2a5-4c1d-8276-53f64e3fc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16689441-3e66-4434-b7dc-256d71fecd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "574c31aa-c882-416e-933b-c06273ad0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4007848-bc01-4fd1-bd2d-5bde58243664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "\n",
    "model = resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f9228b-a6d2-4f40-a117-385593b174aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 37, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c43a7b-7a46-4c62-81bb-8ca73f657a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3071120c-dfc1-49d2-9ee1-8eeb999048ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.children())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "585c1494-6a2f-4bd3-a810-23588e0621bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in list(model.children())[:-1]:\n",
    "    if hasattr(layer, \"requires_grad_\"):\n",
    "        layer.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7448fc-fdb6-4c9e-b3ea-85e944e3ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d366e09d-c9e2-4b28-8f30-f088e14e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from fastai.optimizer import OptimWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01628357-f76d-4467-b8a9-f1380fed315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(OptimWrapper, opt=AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9c81149-a93b-44d4-af8c-f06b204c5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.schedule import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f81ad8ff-80ba-4a1d-a9d7-5cfec97c6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6515ef3-baeb-4a95-a09a-c1a543f7f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls, \n",
    "    model, \n",
    "    opt_func=opt_func, \n",
    "    loss_func=CrossEntropyLossFlat(), \n",
    "    metrics=accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "913da4a0-2f49-449c-a585-e040d7693111",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7134a0a-3a0f-41cb-abbe-c5c325d8f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c8ccb91-2029-4f94-be4e-7b8b4466896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(filenames[0])\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e1ba32d-1442-4026-8ae7-16f5c4b4d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "323e789a-e245-468b-bbbe-711615c03aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_x = valid_transforms(ToTensor()(im))\n",
    "tfm_x = tfm_x.unsqueeze(0); tfm_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594e87b-2455-4aa5-a7bd-e0878357932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    preds = net(tfm_x.cuda())\n",
    "pred = preds.argmax(dim=-1)[0]\n",
    "label = list(label_to_int.keys())[pred]\n",
    "pred, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128835a8-b396-49de-8434-f4ac5fbdac51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
